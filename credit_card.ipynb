{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  BILL_SEPT  BILL_AUG  BILL_JULY  BILL_JUNE  BILL_MAY  BILL_APRIL  \\\n",
      "0   1       3913      3102        689          0         0           0   \n",
      "1   2       2682      1725       2682       3272      3455        3261   \n",
      "2   3      29239     14027      13559      14331     14948       15549   \n",
      "3   4      46990     48233      49291      28314     28959       29547   \n",
      "4   5       8617      5670      35835      20940     19146       19131   \n",
      "\n",
      "   PAY_SEPT  PAY_AUG  PAY_JULY  PAY_JUNE  PAY_MAY  PAY_APRIL  AGE     SEX  \\\n",
      "0         0      689         0         0        0          0   24  Female   \n",
      "1         0     1000      1000      1000        0       2000   26  Female   \n",
      "2      1518     1500      1000      1000     1000       5000   34  Female   \n",
      "3      2000     2019      1200      1100     1069       1000   37  Female   \n",
      "4      2000    36681     10000      9000      689        679   57    Male   \n",
      "\n",
      "    EDUCATION MARRIAGE DEFAULT  \n",
      "0  University  Married     Yes  \n",
      "1  University   Single     Yes  \n",
      "2  University   Single      NO  \n",
      "3  University  Married      NO  \n",
      "4  University  Married      NO  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import data\n",
    "data = pd.read_csv(\"credit_card_train.csv\", header=0)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "---\n",
      "(21000, 18)\n",
      "---\n",
      "ID             int64\n",
      "BILL_SEPT      int64\n",
      "BILL_AUG       int64\n",
      "BILL_JULY      int64\n",
      "BILL_JUNE      int64\n",
      "BILL_MAY       int64\n",
      "BILL_APRIL     int64\n",
      "PAY_SEPT       int64\n",
      "PAY_AUG        int64\n",
      "PAY_JULY       int64\n",
      "PAY_JUNE       int64\n",
      "PAY_MAY        int64\n",
      "PAY_APRIL      int64\n",
      "AGE            int64\n",
      "SEX           object\n",
      "EDUCATION     object\n",
      "MARRIAGE      object\n",
      "DEFAULT       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "viewdata = pd.DataFrame(data)\n",
    "\n",
    "print(viewdata.ndim)\n",
    "print(\"---\") # 分隔線\n",
    "print(viewdata.shape)\n",
    "print(\"---\") # 分隔線\n",
    "print(viewdata.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7785714285714286\n"
     ]
    }
   ],
   "source": [
    "#define feature values and target values\n",
    "feature1 = data.iloc[:, 1:14]\n",
    "#string data\n",
    "feature2 = pd.get_dummies(data.iloc[:,14:17])\n",
    "\n",
    "feature = pd.concat([feature1,feature2],axis=1).values\n",
    "target = data['DEFAULT'].values\n",
    "\n",
    "# split the data into 80% as training sets, 20% as test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=50)\n",
    "\n",
    "# construct the model\n",
    "model1 = SVC()\n",
    "\n",
    "# training model\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "results = model1.predict(x_test)\n",
    "\n",
    "print(model1.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7533333333333333\n"
     ]
    }
   ],
   "source": [
    "#using another method :KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#define feature values and target values\n",
    "feature1 = data.iloc[:, 1:14]\n",
    "#string data\n",
    "feature2 = pd.get_dummies(data.iloc[:,14:17])\n",
    "\n",
    "feature = pd.concat([feature1,feature2],axis=1).values\n",
    "target = data['DEFAULT'].values\n",
    "\n",
    "# split the data into 80% as training sets, 20% as test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=50)\n",
    "\n",
    "\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(x_train,y_train)\n",
    "\n",
    "# make prediction\n",
    "results = model2.predict(x_test)\n",
    "\n",
    "print(model2.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7783333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#define feature values and target values\n",
    "feature1 = data.iloc[:, 1:14]\n",
    "#string data\n",
    "feature2 = pd.get_dummies(data.iloc[:,14:17])\n",
    "\n",
    "feature = pd.concat([feature1,feature2],axis=1).values\n",
    "target = data['DEFAULT'].values\n",
    "\n",
    "# split the data into 80% as training sets, 20% as test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=50)\n",
    "\n",
    "#define feature values and target values\n",
    "feature1 = data.iloc[:, 1:14]\n",
    "#string data\n",
    "feature2 = pd.get_dummies(data.iloc[:,14:17])\n",
    "\n",
    "feature = pd.concat([feature1,feature2],axis=1).values\n",
    "target = data['DEFAULT'].values\n",
    "\n",
    "# split the data into 80% as training sets, 20% as test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=50)\n",
    "\n",
    "model3 = RandomForestClassifier()\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "# make prediction\n",
    "results = model3.predict(x_test)\n",
    "\n",
    "print(model3.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7752380952380953\n"
     ]
    }
   ],
   "source": [
    "# import the LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "\n",
    "#define feature values and target values\n",
    "feature1 = data.iloc[:, 1:14]\n",
    "#string data\n",
    "feature2 = pd.get_dummies(data.iloc[:,14:17])\n",
    "\n",
    "feature = pd.concat([feature1,feature2],axis=1).values\n",
    "target = data['DEFAULT'].values\n",
    "\n",
    "# split the data into 80% as training sets, 20% as test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=50)\n",
    " \n",
    "model4 = LogisticRegression()  \n",
    "model4.fit(x_train,y_train)  \n",
    "\n",
    "\n",
    "# make prediction\n",
    "results = model4.predict(x_test)\n",
    "\n",
    "print(model4.score(x_test, y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
